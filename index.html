
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="./css/style.css">
    <title>AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds
</title>
  </head>
  <body>
    <header class="page-header" role="banner">
      <h1 class="project-name">AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds</h1>
      <h2>ICCV 2021 (oral)</h2>
      <div class="btn-group-flex">
        <a href="https://arxiv.org/abs/2108.05836" class="btn"><img src="./images/paper.svg" class="icon-paper"/>Paper</a>
        <a href="https://github.com/Runsong123/AdaFit" class="btn"><img src="./images/paper.svg" class="icon-paper"/>code</a>
        <!-- <a href="https://github.com/Runsong123/AdaFit" class="btn"><img src="./images/paper.svg" class="icon-paper"/></a> -->
        <!-- <a href="" class="btn"><img src="assets/images/icons/dataset.svg" class="icon-dataset"/>H3DS dataset</a> -->
      </div>
      <div class="authors">
        <p class="authors__name">Runsong zhu<sup>1</sup></p>,
        <p class="authors__name">Yuan Liu<sup>2</sup></p>,
        <p class="authors__name">Zhen Dong<sup>1</sup></p>,
        <p class="authors__name">Tengping Jiang<sup>1</sup></p>,
        <p class="authors__name">Yuan Wang<sup>1</sup></p>,
        <p class="authors__name">Wenping Wang<sup>2,3</sup></p>,
        <p class="authors__name">Bisheng Yang<sup>1</sup></p>
      </div>
      <div class="affiliations">
        <p class="affiliation__name"><sup>1</sup>Wuhan University</p>,
        <p class="affiliation__name"><sup>2</sup>The University of Hong Kong</p>,
        <p class="affiliation__name"><sup>3</sup>Texas A&M University</p>
        <!-- <p class="affiliation__name"><sup>3</sup>Institut de Robòtica i Informàtica Industrial, CSIC-UPC</p> -->
      </div>
      <!-- <div>
        <p>  (* Equal contribution) </p>
      </div> -->
    </header>

    <main id="content" class="main-content" role="main">
      <p><img src="./images/teaser_new_colorbar.png" alt="" /></p>

<h2 id="Abstract">Abstract</h2>

<p>This paper presents a neural network for robust normal estimation on point clouds, named AdaFit, that can deal with point clouds with noise and density variations. Existing works use a network to learn point-wise weights for weighted least squares surface fitting to estimate the normal, which has difficulty in finding accurate normals in complex regions or containing noisy points. By analyzing the step of weighted least squares surface fitting, we find that it is hard to determine the polynomial order of the fitting surface and the fitting surface is sensitive to outliers. To address these problems, we propose a simple yet effective solution that adds an additional offset prediction to improve the quality of normal estimation. Furthermore, in order to take advantage of points from different neighborhood sizes, a novel Cascaded Scale Aggregation layer is proposed to help the network predict more accurate point-wise offsets and weights. Extensive experiments demonstrate that AdaFit achieves state-of-the-art performance on both the synthetic PCPNet dataset and the real-word SceneNN dataset.</p>

<!-- <h2 id="Introduction">Method</h2>
<p>Given the input point cloud, our target is to estimate a normal for every point.</p>

<p><img src="/h3d-net/assets/images/method.png" alt="" /></p> -->

<h2 id="Result comparison">Results</h2>

<!-- <p>Results for PCPNet dataset and real-word SceneNN datasets.</p> -->


<!-- <p>Next, we show full head 3D reconstructions from only 3 input images. In these examples, the camera poses have been regressed using a pre-trained <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Ramon_Hyperparameter-Free_Losses_for_Model-Based_Monocular_Reconstruction_ICCVW_2019_paper.pdf">MRL model</a>, which minimizes the reprojection error. The masks have been estimated using <a href="https://arxiv.org/pdf/2005.09007.pdf">U2Net</a> and then have been manually refined.</p> -->

<figure align="center">
  <p align="center"><img src="./images/PCPNet_error_map.png" width="700" />
  <figcaption> a). Errors of normal estimation on the PCPNet dataset.
  </figcaption>
  </p>
</figure>


<figure align="center">
  <p align="center"><img src="./images/indoor.png" width="700" />
  <figcaption> b). Errors of normal estimation on the SceneNN dataset.
  </figcaption>
  </p>
</figure>

<!-- <p align="center">
  <img src="./images/PCPNet_error_map.png" width="700" />
</p>
<p align="center">
    <img src="./images/indoor.png" width="700" />
</p> -->
<!-- <p>We also provide a qualitative and quantitative comparison with respect to <a href="https://arxiv.org/abs/2003.09852">IDR</a> varying the number of available views. Note how H3D-Net effectively finds realistic and detailed solutions in both few-shot and many-shot scenarios.</p>

<p align="center">
  <img src="assets/images/h3dnet-idr.gif" />
</p> -->



<!-- <h2 id="downstreams target">downstreams target </h2> -->



<h2>Application</h2>

<figure align="center">
  <p align="center"><img src="./images/Surface.png" width="700" />
  <figcaption> a). The comparison of the Poisson surface reconstruction using the estimated normals from different methods.
  </figcaption>
  </p>
</figure>


<figure align="center">
  <p align="center">
    <img src="./images/denoise.png" width="700" />
    <figcaption> b). Qualitative results of point cloud denoising. The first row shows the denoised point clouds while the second row shows the corresponding reconstructed surfaces.</figcaption>
    <!-- <h3>denoise</h3> -->
  </figcaption>
  </p>
</figure>



<!-- 
<p align="center">
  <img src="./images/Surface.png" width="700" />
  <div style="text-align:center"><p3>The comparison of the Poisson surface reconstruction using the estimated normals from different methods.</p3></div>
</p> -->

<!-- <h2>Denoising</h2> -->
<!-- <p align="center">
    <img src="./images/denoise.png" width="700" />
    <div style="text-align:center"><p5>Qualitative results of point cloud denoising. The first row shows the denoised point clouds while the second row shows the corresponding reconstructed surfaces.</p5></div>
    <!-- <h3>denoise</h3> -->
<!-- </p> --> 

<h2 id="Short video">Short video</h2>
<p align="center">
    <video width="700" controls>
        <source src="./images/Column_surface.mp4" type="video/mp4"> 
    </video>
    <!-- <img src="./images/Column_surface.gif" width="700" /> -->
  </p>

  <p align="center">
    <video width="700" controls>
        <source src="./images/denoise.mp4" type="video/mp4"> 
    </video>
    <!-- <img src="./images/Column_surface.gif" width="700" /> -->
  </p>
  <!-- <p align="center">
      <img src="./images/denoise.mp4" width="700" />
  </p> -->

<h2 id="related-work">Related work</h2>

<ol>
  <li><a href="https://arxiv.org/abs/1710.04954">PCPNET: Learning Local Shape Properties from Raw Point Clouds (2018)</a></li>
  <li><a href="https://arxiv.org/abs/1904.07172">Deep Iterative Surface Normal Estimation (2020)</a></li>
  <li><a href="https://arxiv.org/abs/2003.10826">DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares (2020)</a></li>
</ol>

<h2 id="bibtex">BibTeX</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{2108.05836,
Author = {Runsong Zhu and Yuan Liu and Zhen Dong and Tengping Jiang and Yuan Wang and Wenping Wang and Bisheng Yang},
Title = {AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds},
Year = {2021},
Eprint = {arXiv:2108.05836},
</code></pre></div></div>


      <footer class="site-footer">
        We use the code from https://crisalixsa.github.io/h3d-net/
      </footer>
    </main>
  </body>
</html>
